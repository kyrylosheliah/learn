{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d24a0f-bf31-449b-90f1-61912a4c9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "237a30f7-9086-4e62-b0f6-88a793f5c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Leaky_ReLU:\n",
    "    def forward(x):\n",
    "        data = [[max(0.05*value,value) for value in row] for row in x]\n",
    "        return np.array(data, dtype=float)\n",
    "    def backward(x):\n",
    "        data = [[1 if value>0 else 0.05 for value in row] for row in x]\n",
    "        return np.array(data, dtype=float)\n",
    "\n",
    "class ReLU:\n",
    "    def forward(x):\n",
    "        return np.maximum(0, x)\n",
    "    def backward(x):\n",
    "        return 1. * (x > 0)\n",
    "\n",
    "class tanh:\n",
    "    def forward(x):\n",
    "        return np.tanh(x);\n",
    "    def backward(x):\n",
    "        return 1-np.tanh(x)**2;\n",
    "\n",
    "class sigmoid:\n",
    "    def forward(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def backward(x):\n",
    "        fx = sigmoid.forward(x)\n",
    "        return fx*(1-fx)\n",
    "\n",
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_pred-y_true, 2))\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*np.mean(y_pred-y_true)\n",
    "\n",
    "# Base class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, function):\n",
    "        self.activation = function.forward\n",
    "        self.activation_prime = function.backward\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "\n",
    "class FCLayer(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size)\n",
    "        self.bias = np.random.rand(1, output_size)\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n",
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        for i in range(samples):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "        return result\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        x_train = np.array([[elem] for elem in x_train])\n",
    "        y_train = np.array([[elem] for elem in y_train])\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "                err += self.loss(y_train[j], output)\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "            #err /= samples\n",
    "            #if (i+1)%1000 == 0:\n",
    "            #    print('i %d | err %f' % (i+1, err))\n",
    "        print('epochs=%d, error=%f, learning_rate=%f' % (epochs, err, learning_rate))\n",
    "        return err\n",
    "        \n",
    "def DisplayPurpose(y_train, out):\n",
    "    for i in range(len(y_train)):\n",
    "        print(y_train[i], end = '')\n",
    "        print(\" ->\\t \", end = '')\n",
    "        print(out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7c67308c-436b-42d8-ad3a-5c8f34a15190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diff=30.000000, bias=15.000000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'diff=28771.875000, bias=14385.937500'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=1000, error=0.468277, learning_rate=0.100000\n",
      "epochs=1000, error=0.123279, learning_rate=0.066667\n",
      "epochs=1000, error=0.088810, learning_rate=0.044444\n",
      "epochs=1000, error=0.072169, learning_rate=0.029630\n",
      "epochs=1000, error=0.062160, learning_rate=0.019753\n",
      "epochs=1000, error=0.055801, learning_rate=0.013169\n",
      "epochs=1000, error=0.051705, learning_rate=0.008779\n",
      "epochs=1000, error=0.049055, learning_rate=0.005853\n",
      "epochs=1000, error=0.047329, learning_rate=0.003902\n",
      "epochs=1000, error=0.046200, learning_rate=0.002601\n",
      "[1.0009775171065494] ->\t [[0.84335338]]\n",
      "[0.5004887585532747] ->\t [[0.62302094]]\n",
      "[0.25024437927663734] ->\t [[0.22335093]]\n",
      "[0.12512218963831867] ->\t [[0.08616594]]\n",
      "[0.06256109481915934] ->\t [[0.07053539]]\n",
      "[0.03128054740957967] ->\t [[0.05487012]]\n",
      "[0.015640273704789834] ->\t [[0.0391778]]\n",
      "[0.007820136852394917] ->\t [[0.02346612]]\n",
      "[0.0039100684261974585] ->\t [[0.00774285]]\n",
      "[0.0019550342130987292] ->\t [[-0.00798425]]\n",
      "[0.0009775171065493646] ->\t [[-0.02370741]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[85],[88],[91],[94],[97],[100],[103],[106],[109],[112],[115]])\n",
    "y_train = np.array([[28800],[14400],[7200],[3600],[1800],[900],[450],[225],[112.5],[56.25],[28.125]])\n",
    "\n",
    "def minus_avg(x):\n",
    "    data = []\n",
    "    minimum = 9999999999\n",
    "    maximum = -9999999999\n",
    "    for row in x:\n",
    "        for value in row:\n",
    "            if minimum > value:\n",
    "                minimum = value\n",
    "            if maximum < value:\n",
    "                maximum = value\n",
    "    diff = maximum - minimum\n",
    "    bias = diff / 2\n",
    "    for row in x:\n",
    "        data.append([])\n",
    "        for value in row:\n",
    "            #data[-1].append((value - bias)/bias)\n",
    "            data[-1].append(value/diff)\n",
    "    display(\"diff=%f, bias=%f\"%(diff, bias))\n",
    "    return data, diff, bias\n",
    "x_train, x_diff, x_bias = minus_avg(x_train)\n",
    "y_train, y_diff, y_bias = minus_avg(y_train)\n",
    "\n",
    "net = Network()\n",
    "net.add(FCLayer(len(x_train[0]), 5))\n",
    "net.add(ActivationLayer(Leaky_ReLU))\n",
    "net.add(FCLayer(5, len(y_train[0])))\n",
    "net.add(ActivationLayer(tanh))\n",
    "net.use(mse, mse_prime)\n",
    "lr = 0.1\n",
    "for i in range(10):\n",
    "    net.fit(x_train, y_train, epochs=1000, learning_rate=lr)\n",
    "    lr /= 1.5\n",
    "\n",
    "out = net.predict(x_train)\n",
    "DisplayPurpose(y_train, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a4d85f46-9d4d-41c1-86bd-b31bd780c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85] ->\t [[24562.60215372]]\n",
      "[86] ->\t [[22447.25921888]]\n",
      "[87] ->\t [[19663.08622931]]\n",
      "[88] ->\t [[16332.4808861]]\n",
      "[89] ->\t [[12774.82094236]]\n",
      "[90] ->\t [[9406.12882888]]\n",
      "[91] ->\t [[7354.01568221]]\n",
      "[92] ->\t [[5812.00281266]]\n",
      "[93] ->\t [[4525.01228691]]\n",
      "[94] ->\t [[3479.81582079]]\n",
      "[95] ->\t [[2649.65877386]]\n",
      "[96] ->\t [[2001.87158358]]\n",
      "[97] ->\t [[1503.34079037]]\n",
      "[98] ->\t [[1131.57173162]]\n",
      "[99] ->\t [[941.42793949]]\n",
      "[100] ->\t [[782.33064651]]\n",
      "[101] ->\t [[649.49264578]]\n",
      "[102] ->\t [[538.77606465]]\n",
      "[103] ->\t [[446.6331812]]\n",
      "[104] ->\t [[370.04227139]]\n",
      "[105] ->\t [[306.4434615]]\n",
      "[106] ->\t [[253.67768817]]\n",
      "[107] ->\t [[209.93052254]]\n",
      "[108] ->\t [[173.68168674]]\n",
      "[109] ->\t [[143.66047831]]\n",
      "[110] ->\t [[118.80693475]]\n",
      "[111] ->\t [[98.23834826]]\n",
      "[112] ->\t [[81.22062785]]\n",
      "[113] ->\t [[67.1439652]]\n",
      "[114] ->\t [[55.50226408]]\n",
      "[115] ->\t [[45.87582378]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[i] for i in range(85, 116)])\n",
    "out = net.predict(arr/x_diff)\n",
    "DisplayPurpose(arr, np.array(out)*y_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111b5ce-c8cf-4502-be81-6928537bcb69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
